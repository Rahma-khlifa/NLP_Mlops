name: CI

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]
  workflow_dispatch:

env:
  PYTHONUNBUFFERED: 1
  MLFLOW_EXPERIMENT: tunsentt

jobs:
  ci:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
      id-token: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies (including Evidently AI)
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Ajout de evidently et pandas pour le monitoring de dérive
          pip install dvc[s3] dagshub mlflow openpyxl evidently pandas

      - name: Configure DVC remote
        run: |
          dvc remote add dagshub-ci https://dagshub.com/rahmmaakhlefa/NLP_Mlops.dvc || true
          dvc remote modify dagshub-ci auth basic
          dvc remote modify dagshub-ci user ${{ secrets.DAGSHUB_USERNAME }}
          dvc remote modify dagshub-ci password ${{ secrets.DAGSHUB_TOKEN }}
          # Ajout de commandes de débogage
          echo "DVC Remote Configuration:"
          dvc remote list -v
          
          echo "DVC Cache Status (should be empty in CI ):"
          dvc cache dir
          
          echo "DVC Status (should show files to pull):"
          dvc status
          dvc doctor

      - name: DVC Pull and Checkout All Tracked Files
        run: |
          echo "Executing DVC Pull and Checkout for all tracked files..."
          
          # 1. Pull tous les fichiers DVC suivis par le commit actuel
          # Le -f (force) est souvent nécessaire dans les environnements CI
          dvc pull -r dagshub-ci -v 
          
          # 2. Checkout pour restaurer les fichiers de données
          dvc checkout
          
          # 3. Afficher le contenu du répertoire de données pour le débogage
          echo "Contenu du répertoire data/ après checkout :"
          ls -l data/
          
          # 4. Vérification de la présence des fichiers
          if [ ! -f "data/version1.xlsx" ]; then
            echo "❌ ERROR: data/version1.xlsx not found after dvc checkout!"
            exit 1
          fi
          if [ ! -f "data/version2.xlsx" ]; then
            echo "❌ ERROR: data/version2.xlsx not found after dvc checkout!"
            exit 1
          fi
          echo "✅ All required data files are present."



      - name: Verify data presence
        run: |
          echo "Checking data directory content:"
          ls -R data/
          if [ ! -f "data/version1.xlsx" ]; then
            echo "❌ ERROR: data/version1.xlsx not found after dvc pull!"
            exit 1
          fi
          if [ ! -f "data/version2.xlsx" ]; then
            echo "❌ ERROR: data/version2.xlsx not found after dvc pull!"
            exit 1
          fi
          echo "✅ data/version1.xlsx and data/version2.xlsx are present"

      - name: Install backend requirements
        run: pip install -r backend/requirements.txt || echo "No backend requirements found"

      - name: Run Data Drift Check with Evidently AI
        id: drift_check
        run: |
          # Créer le répertoire pour les rapports Evidently
          mkdir -p evidently_reports
          # Exécuter le script de détection de dérive et capturer la sortie
          python scripts/run_evidently.py
          
      - name: Run training
        if: steps.drift_check.outputs.drift_status == 'DRIFT_DETECTED'
        env:
          DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME }}
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
          GITHUB_ACTIONS: "true"
        run: python scripts/train.py

      - name: Register best model
        if: steps.drift_check.outputs.drift_status == 'DRIFT_DETECTED'
        env:
          DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME }}
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: python scripts/register_best_model.py

      - name: Check model output
        if: steps.drift_check.outputs.drift_status == 'DRIFT_DETECTED'
        run: |
          echo "Checking model registry content:"
          ls -R model_registry/ || echo "No model_registry directory found"

  deploy:
    needs: ci
    if: github.ref == 'refs/heads/master'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install requirements for registration
        run: |
          pip install -r requirements.txt

      - name: Download production artifacts (Model + Vectorizer)
        run: |
          python scripts/register_best_model.py
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
          DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
          DAGSHUB_REPO_NAME: ${{ secrets.DAGSHUB_REPO_NAME }}

      - name: Prepare VM directories
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.VM_IP }}
          username: ${{ secrets.VM_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            mkdir -p ~/NLP_Mlops/model_registry
            sudo chown -R ${{ secrets.VM_USER }}:${{ secrets.VM_USER }} ~/NLP_Mlops
            sudo chmod -R 755 ~/NLP_Mlops

      - name: Copy artifacts to Azure VM
        uses: appleboy/scp-action@master
        with:
          host: ${{ secrets.VM_IP }}
          username: ${{ secrets.VM_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          source: "model_registry/"
          target: "~/NLP_Mlops/"
          rm: false

      - name: Deploy to Azure VM via SSH
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.VM_IP }}
          username: ${{ secrets.VM_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            cd ~/NLP_Mlops
            
            # Ensure we are in a valid git repo (Fix for broken VM state)
            if [ ! -d ".git" ]; then
              echo "⚠️ .git not found. Initializing..."
              git init
              git remote add origin https://github.com/Rahma-khlifa/NLP_Mlops.git
            fi

            # Force sync with 'master'
            git fetch origin master
            git reset --hard origin/master
            
            # Restart with docker-compose
            docker-compose down || true
            docker-compose up -d --build
            
            # Clean up
            docker image prune -f
